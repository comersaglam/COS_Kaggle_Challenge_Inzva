{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-26T13:57:31.512282Z",
     "iopub.status.busy": "2024-11-26T13:57:31.511652Z",
     "iopub.status.idle": "2024-11-26T13:57:32.269064Z",
     "shell.execute_reply": "2024-11-26T13:57:32.268082Z",
     "shell.execute_reply.started": "2024-11-26T13:57:31.512244Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T13:57:32.272354Z",
     "iopub.status.busy": "2024-11-26T13:57:32.271213Z",
     "iopub.status.idle": "2024-11-26T13:57:32.373312Z",
     "shell.execute_reply": "2024-11-26T13:57:32.372583Z",
     "shell.execute_reply.started": "2024-11-26T13:57:32.272306Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#* import cleaned text\n",
    "\n",
    "df_train = pd.read_csv(\"/kaggle/input/nlp-disaster-tweets/train_cleaned.csv\")\n",
    "df_test = pd.read_csv(\"/kaggle/input/nlp-disaster-tweets/test_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T13:57:32.374538Z",
     "iopub.status.busy": "2024-11-26T13:57:32.374292Z",
     "iopub.status.idle": "2024-11-26T13:57:32.394036Z",
     "shell.execute_reply": "2024-11-26T13:57:32.393063Z",
     "shell.execute_reply.started": "2024-11-26T13:57:32.374513Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T13:57:32.395206Z",
     "iopub.status.busy": "2024-11-26T13:57:32.394999Z",
     "iopub.status.idle": "2024-11-26T13:57:32.406495Z",
     "shell.execute_reply": "2024-11-26T13:57:32.405623Z",
     "shell.execute_reply.started": "2024-11-26T13:57:32.395185Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T13:57:32.408653Z",
     "iopub.status.busy": "2024-11-26T13:57:32.408410Z",
     "iopub.status.idle": "2024-11-26T13:57:54.791507Z",
     "shell.execute_reply": "2024-11-26T13:57:54.790814Z",
     "shell.execute_reply.started": "2024-11-26T13:57:32.408629Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW, RobertaTokenizer, RobertaForSequenceClassification\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Dataset preparation\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df_train[\"text_cleaned\"], df_train[\"target\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "\n",
    "#tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "#model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=128)\n",
    "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T13:57:54.792935Z",
     "iopub.status.busy": "2024-11-26T13:57:54.792526Z",
     "iopub.status.idle": "2024-11-26T13:57:54.798862Z",
     "shell.execute_reply": "2024-11-26T13:57:54.797859Z",
     "shell.execute_reply.started": "2024-11-26T13:57:54.792906Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class DisasterDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None, device=\"cuda:0\"):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])  \n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels is not None:  # Add labels only if they exist\n",
    "            item['labels'] = torch.tensor(self.labels[idx]).to(self.device)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T13:57:54.800347Z",
     "iopub.status.busy": "2024-11-26T13:57:54.800034Z",
     "iopub.status.idle": "2024-11-26T13:57:57.086860Z",
     "shell.execute_reply": "2024-11-26T13:57:57.082708Z",
     "shell.execute_reply.started": "2024-11-26T13:57:54.800311Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = DisasterDataset(train_encodings, train_labels.tolist(), device= device)\n",
    "val_dataset = DisasterDataset(val_encodings, val_labels.tolist(), device = device)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# Optimizer\n",
    "# optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),           # Model parameters to optimize\n",
    "    lr=1e-5,                      # Learning rate (commonly 2e-5 to 5e-5 for BERT/RoBERTa)\n",
    "    betas=(0.9, 0.999),           # Beta values for Adam; defaults are typically fine\n",
    "    eps=1e-8,                     # Epsilon for numerical stability\n",
    "    weight_decay=0.01,            # Weight decay to prevent overfitting\n",
    "    correct_bias=True             # Whether to correct bias (default for AdamW)\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "epoch_num =50 \n",
    "for epoch in range(epoch_num):  # Number of epochs\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for batch in loop:\n",
    "        # Move to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step(loss)\n",
    "\n",
    "        # Update progress bar\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-26T13:57:57.087633Z",
     "iopub.status.idle": "2024-11-26T13:57:57.087991Z",
     "shell.execute_reply": "2024-11-26T13:57:57.087851Z",
     "shell.execute_reply.started": "2024-11-26T13:57:57.087825Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predictions\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "for batch in val_loader:\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "    all_preds.extend(preds.cpu().numpy())\n",
    "    all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(all_labels, all_preds)\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-26T13:57:57.089123Z",
     "iopub.status.idle": "2024-11-26T13:57:57.089421Z",
     "shell.execute_reply": "2024-11-26T13:57:57.089295Z",
     "shell.execute_reply.started": "2024-11-26T13:57:57.089280Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-26T13:57:57.091018Z",
     "iopub.status.idle": "2024-11-26T13:57:57.091314Z",
     "shell.execute_reply": "2024-11-26T13:57:57.091189Z",
     "shell.execute_reply.started": "2024-11-26T13:57:57.091173Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_sentences = list(df_test['text'].values)\n",
    "#test_encodings = tokenizer(test_sentences, truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(list(df_test['text']), truncation=True, padding=True, max_length=128)\n",
    "\n",
    "#test_inputs = torch.tensor(test_encodings['input_ids'])\n",
    "#test_masks = torch.tensor(test_encodings['attention_mask'])\n",
    "\n",
    "#test_data = DisasterDataset(test_inputs, test_masks, torch.zeros(len(test_inputs)))  # No labels in test set\n",
    "#test_loader = DataLoader(test_data, batch_size=16)\n",
    "\n",
    "test_data = DisasterDataset(test_encodings)\n",
    "test_loader = DataLoader(test_data, batch_size=16)\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels = labels)\n",
    "        logits = outputs.logits\n",
    "        predictions.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
    "\n",
    "submission = pd.DataFrame({'id': df_test['id'], 'target': predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6169872,
     "sourceId": 10020016,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
